services:
  ollama:
    build:
      context: .
      dockerfile: Dockerfile.ollama
    container_name: ${OLLAMA_TEXT_HOST}
    ports:
      - "${OLLAMA_TEXT_PORT}:11434"
    volumes:
      # Volume Docker pour persister les modèles téléchargés
      - ollama_models:/root/.ollama
    env_file: .env
    environment:
      - OLLAMA_HOST=0.0.0.0
      - NVIDIA_VISIBLE_DEVICES=all
      - OLLAMA_NUM_PARALLEL=1
      - OLLAMA_LLM_LIBRARY=cuda
    restart: unless-stopped
    gpus: all

  fastapi:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: fastapi
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app/backend
      - ./utils:/app/utils
      - ./data:/app/data
    env_file: .env
    depends_on:
      - ollama
      - stablediffusion
      - postgres
      - mongo

  stablediffusion:
    image: universonic/stable-diffusion-webui:full
    container_name: ${STABLEDIFFUSION_HOST}
    ports:
      - "${STABLEDIFFUSION_PORT}:8080"
    volumes:
      - sd_models:/app/stable-diffusion-webui/models
      - sd_outputs:/app/stable-diffusion-webui/outputs
    env_file: .env
    restart: unless-stopped
    gpus: all

  postgres:
    image: postgres:16
    container_name: postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  mongo:
    image: mongo:6
    container_name: mongo
    restart: unless-stopped
    volumes:
      - mongo_data:/data/db
    ports:
      - "27017:27017"

volumes:
  ollama_models:
  sd_models:
  sd_outputs:
  postgres_data:
  mongo_data:
