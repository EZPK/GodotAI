# ğŸ¤– GodotAI

GodotAI combine plusieurs briques pour crÃ©er une expÃ©rience de jeu pilotÃ©e par un LLM. âœ¨ Ce README rÃ©capitule chaque composant et explique comment lancer le projet.

## ğŸ§© Composants

### 1. âš¡ FastAPI
- Sert d'API REST.
- Expose des routes pour gÃ©nÃ©rer du texte et des images via Ollama.
- ImplÃ©mente le Model Context Protocol (MCP) pour dÃ©crire prompts, outils et ressources.
- Stocke utilisateurs, sessions et messages avec SQLAlchemy dans `game.db`.
- Conserve un contexte rÃ©cent en mÃ©moire grÃ¢ce Ã  `EmbeddingContext`.

### 2. ğŸ¦™ Ollama
- Service LLM exÃ©cutÃ© dans un conteneur dÃ©diÃ©.
- Le Dockerfile personnalise l'image officielle et lance `entrypoint_ollama.sh` pour tÃ©lÃ©charger automatiquement le modÃ¨le choisi (`OLLAMA_TEXT_MODEL`).
- Support GPU via NVIDIA Container Toolkit.
- Les paramÃ¨tres par dÃ©faut du modÃ¨le sont dÃ©finis dans `Modelfile`.

### 3. ğŸ® Godot
- Client graphique basÃ© sur Godot 4.
- Les scripts `ChatUI.gd` et `ApiCallHeadless.gd` communiquent avec le backend par HTTP.
- Permet de tester rapidement l'API en mode Ã©diteur ou en ligne de commande.

### 4. ğŸ³ Docker Compose
- Orchestration des services `ollama` et `backend`.
- Monte un volume `ollama_models` pour conserver les modÃ¨les tÃ©lÃ©chargÃ©s.
- Les variables d'environnement (GPU, nom du modÃ¨le, etc.) sont configurables dans `docker-compose.yml`.

### 5. ğŸ“š MkDocs
- La documentation vit dans le dossier `docs/` et peut Ãªtre servie via `mkdocs serve`.
- Le dÃ©ploiement sur GitHub Pages est gÃ©rÃ© par `mkdocs gh-deploy` (voir Makefile).

## ğŸš€ Lancer le projet
```bash
# 1. cloner le dÃ©pÃ´t
$ git clone <repo_url>
$ cd godot_ai

# 2. dÃ©marrer Ollama et l'API
$ make up

# 3. ouvrir le client Godot (facultatif)
$ make run-godot
```
- Ollama Ã©coute sur `localhost:11434` et tÃ©lÃ©charge le modÃ¨le au premier dÃ©marrage.
- Le backend est disponible sur `localhost:8000` (voir `backend/app/backend_server.py`).

Pour arrÃªter les services :
```bash
$ make down
```

## ğŸ“ Model Context Protocol
L'endpoint `/mcp` parle JSON-RPC 2.0. Il permet :
- d'initialiser un client (`initialize`),
- de lister prompts, ressources et outils disponibles.

Ceci simplifie l'intÃ©gration d'agents compatibles MCP.

## ğŸ¨ Personnalisation
- Changez le modÃ¨le via `OLLAMA_TEXT_MODEL` dans `.env` ou `docker-compose.yml`.
- Modifiez le prompt systÃ¨me dans `Modelfile`.
- Ajoutez vos propres routes dans `backend/app` ou scripts dans `godot/`.

## ğŸ“š Documentation
Une doc synthÃ©tique est disponible dans `docs/`. Servez-la en local avec :
```bash
mkdocs serve
```
ou dÃ©ployez-la via :
```bash
mkdocs gh-deploy --clean
```

---

Pour toute question, consultez les logs Docker ou ouvrez une issue sur le dÃ©pÃ´t.
