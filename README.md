# ü§ñ GodotAI

GodotAI combine plusieurs briques pour cr√©er une exp√©rience de jeu pilot√©e par un LLM. ‚ú® Ce README r√©capitule chaque composant et explique comment lancer le projet.

## üß© Composants

### 1. ‚ö° FastAPI
- Sert d'API REST.
- Expose des routes pour g√©n√©rer du texte et des images via Ollama.
- Impl√©mente le Model Context Protocol (MCP) pour d√©crire prompts, outils et ressources.
- Stocke utilisateurs, sessions et messages avec SQLAlchemy dans `game.db`.
- Conserve un contexte r√©cent en m√©moire gr√¢ce √† `EmbeddingContext`.

### 2. ü¶ô Ollama
- Service LLM ex√©cut√© dans un conteneur d√©di√©.
- Le Dockerfile personnalise l'image officielle et lance `entrypoint_ollama.sh` pour t√©l√©charger automatiquement le mod√®le choisi (`OLLAMA_TEXT_MODEL`).
- Support GPU via NVIDIA Container Toolkit.
- Les param√®tres par d√©faut du mod√®le sont d√©finis dans `Modelfile`.

### 3. üéÆ Godot
- Client graphique bas√© sur Godot 4.
- Les scripts `ChatUI.gd` et `ApiCallHeadless.gd` communiquent avec le backend par HTTP.
- Permet de tester rapidement l'API en mode √©diteur ou en ligne de commande.

### 4. üê≥ Docker Compose
- Orchestration des services `ollama`, `ollama_image` et `backend`.
- Monte des volumes `ollama_models` et `ollama_image_models` pour conserver les mod√®les t√©l√©charg√©s.
- Les variables d'environnement (GPU, nom des mod√®les, etc.) sont configurables dans `docker-compose.yml`.

### 5. üìö MkDocs
- La documentation vit dans le dossier `docs/` et peut √™tre servie via `mkdocs serve`.
- Le d√©ploiement sur GitHub Pages est g√©r√© par `mkdocs gh-deploy` (voir Makefile).

## üöÄ Lancer le projet
```bash
# 1. cloner le d√©p√¥t
$ git clone <repo_url>
$ cd godot_ai

# 2. d√©marrer Ollama et l'API
$ make up

# 3. ouvrir le client Godot (facultatif)
$ make run-godot
```
- Ollama √©coute sur `localhost:11434` et t√©l√©charge le mod√®le au premier d√©marrage.
- Le backend est disponible sur `localhost:8000` (voir `backend/app/backend_server.py`).

Pour arr√™ter les services :
```bash
$ make down
```

## üìù Model Context Protocol
L'endpoint `/mcp` parle JSON-RPC 2.0. Il permet :
- d'initialiser un client (`initialize`),
- de lister prompts, ressources et outils disponibles.

Ceci simplifie l'int√©gration d'agents compatibles MCP.

## üé® Personnalisation
- Changez le mod√®le via `OLLAMA_TEXT_MODEL` dans `.env` ou `docker-compose.yml`.
- Modifiez le prompt syst√®me dans `Modelfile`.
- Ajoutez vos propres routes dans `backend/app` ou scripts dans `godot/`.

## üìö Documentation
Une doc synth√©tique est disponible dans `docs/`. Servez-la en local avec :
```bash
mkdocs serve
```
ou d√©ployez-la via :
```bash
mkdocs gh-deploy --clean
```

---

Pour toute question, consultez les logs Docker ou ouvrez une issue sur le d√©p√¥t.
